{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jonathan Hernandez\n",
    "\n",
    "Examining Frequency of words used in Jeopardy Questions.\n",
    "\n",
    "I will look at the corpus of over 200k+ questions from 1984 to around January 2012\n",
    "\n",
    "Data: https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/\n",
    "\n",
    "Download: https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view\n",
    "\n",
    "Reddit User u/trexmatt scraped the Jeopardy data from the below website:\n",
    "http://www.j-archive.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import enchant\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions:  216930\n"
     ]
    }
   ],
   "source": [
    "jeopardy = pd.read_json(\"JEOPARDY_QUESTIONS1.json\")\n",
    "print \"Number of questions: \", len(jeopardy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only the questions that were asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = jeopardy.question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of some of the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    'For the last 8 years of his life, Galileo was...\n",
       "1    'No. 2: 1912 Olympian; football star at Carlis...\n",
       "2    'The city of Yuma in this state has a record a...\n",
       "3    'In 1963, live on \"The Art Linkletter Show\", t...\n",
       "4    'Signer of the Dec. of Indep., framer of the C...\n",
       "5    'In the title of an Aesop fable, this insect s...\n",
       "6    'Built in 312 B.C. to link Rome & the South of...\n",
       "7    'No. 8: 30 steals for the Birmingham Barons; 2...\n",
       "8    'In the winter of 1971-72, a record 1,122 inch...\n",
       "9    'This housewares store was named for the packa...\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words are in the dataset?\n",
    "\n",
    "First let's join the questions into on big string as a corpus based on the whitespace character and then tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = enchant.Dict(\"en_US\")\n",
    "# join the list of strings into one\n",
    "corpus = \" \".join(questions)\n",
    "tokens = nltk.word_tokenize(corpus) # tokenize the string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in corpus:  4086745\n"
     ]
    }
   ],
   "source": [
    "words = [w.lower() for w in tokens]\n",
    "n_words = len(words) # total number of words\n",
    "print \"Number of words in corpus: \", n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 4 million words in over 28 years of jeopardy questions!\n",
    "\n",
    "Now let's see which words are actually part of the English language.\n",
    "\n",
    "For this assignment, i'm only considering 2 letters or more with no digits and special characters such as '.' as valid words\n",
    "\n",
    "I'll use regular expressions to filter out based on the above and then use the python enchant package's check() function to see if it is a valid word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  37824\n"
     ]
    }
   ],
   "source": [
    "words_only = [w for w in words if re.search(r\"^[a-z]{1,}[^\\W|\\d]+$\",w)]\n",
    "words_only = [w for w in words_only if d.check(w)] # only if valid in the English Language\n",
    "n_unique_words = len(set(words_only)) \n",
    "print \"Number of unique words: \", n_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running for a few seconds, we see that the Jeopardy corpus of 28 years of questions contains close to 38000 unique English words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the most common words, how many unique represent half of the total words in the corpus?\n",
    "\n",
    "I'll use nltk's FreqDist() function for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words that occur more than half of the total words in corpus:  0\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(words_only) # frequency distribution\n",
    "large_freq = 0 # counter\n",
    "for freq in fdist:\n",
    "    if fdist[freq] > (n_words / 2): # if greater than half the total words\n",
    "        large_freq = large_freq + 1\n",
    "print \"Number of unique words that occur more than half of the total words in corpus: \", large_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that none of the unique words don't even come close to half of the total words in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the 200 highest frequency words in this corpus\n",
    "\n",
    "I'll print out the words and frequencies and the output is in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 159660\n",
      "of 113472\n",
      "this 106279\n",
      "in 80984\n",
      "to 50357\n",
      "for 35403\n",
      "is 34621\n",
      "was 29775\n",
      "on 23269\n",
      "it 20561\n",
      "from 17957\n",
      "with 17247\n",
      "that 15959\n",
      "by 15778\n",
      "his 15589\n",
      "as 15555\n",
      "these 13977\n",
      "he 12793\n",
      "you 12678\n",
      "one 11842\n",
      "an 11547\n",
      "at 11365\n",
      "name 11153\n",
      "or 10274\n",
      "first 9942\n",
      "are 8576\n",
      "its 8213\n",
      "who 7633\n",
      "city 7338\n",
      "here 7020\n",
      "be 6710\n",
      "has 6111\n",
      "and 6022\n",
      "country 5954\n",
      "her 5953\n",
      "man 5522\n",
      "named 5426\n",
      "called 5368\n",
      "state 5289\n",
      "have 5219\n",
      "about 5128\n",
      "can 5051\n",
      "but 4913\n",
      "when 4894\n",
      "seen 4860\n",
      "film 4756\n",
      "new 4745\n",
      "not 4736\n",
      "like 4731\n",
      "clue 4677\n",
      "type 4556\n",
      "were 4370\n",
      "up 4331\n",
      "she 4216\n",
      "made 4044\n",
      "your 3995\n",
      "crew 3982\n",
      "which 3978\n",
      "title 3931\n",
      "used 3881\n",
      "had 3874\n",
      "known 3670\n",
      "world 3605\n",
      "after 3591\n",
      "into 3570\n",
      "out 3515\n",
      "do 3474\n",
      "also 3431\n",
      "no 3426\n",
      "word 3286\n",
      "only 3274\n",
      "all 3253\n",
      "him 3199\n",
      "became 3163\n",
      "said 3152\n",
      "president 3132\n",
      "may 3125\n",
      "years 3058\n",
      "novel 2987\n",
      "played 2986\n",
      "wrote 2955\n",
      "over 2937\n",
      "my 2913\n",
      "they 2875\n",
      "capital 2862\n",
      "king 2715\n",
      "their 2714\n",
      "term 2656\n",
      "than 2612\n",
      "war 2594\n",
      "part 2590\n",
      "book 2541\n",
      "last 2517\n",
      "island 2510\n",
      "show 2489\n",
      "most 2480\n",
      "won 2478\n",
      "been 2402\n",
      "famous 2369\n",
      "french 2362\n",
      "before 2345\n",
      "more 2336\n",
      "home 2331\n",
      "time 2286\n",
      "what 2285\n",
      "song 2256\n",
      "means 2230\n",
      "play 2216\n",
      "people 2204\n",
      "me 2162\n",
      "now 2150\n",
      "river 2147\n",
      "get 2138\n",
      "where 2123\n",
      "company 2117\n",
      "if 2106\n",
      "hit 2106\n",
      "day 2063\n",
      "we 2050\n",
      "group 2043\n",
      "so 2015\n",
      "make 2008\n",
      "great 1992\n",
      "author 1991\n",
      "there 1984\n",
      "woman 1982\n",
      "got 1964\n",
      "whose 1956\n",
      "just 1955\n",
      "national 1940\n",
      "largest 1935\n",
      "john 1930\n",
      "house 1907\n",
      "year 1895\n",
      "star 1879\n",
      "some 1876\n",
      "character 1843\n",
      "found 1842\n",
      "work 1837\n",
      "century 1830\n",
      "old 1811\n",
      "did 1795\n",
      "south 1774\n",
      "little 1771\n",
      "many 1770\n",
      "off 1737\n",
      "life 1726\n",
      "says 1715\n",
      "back 1714\n",
      "other 1691\n",
      "comes 1680\n",
      "them 1678\n",
      "once 1674\n",
      "could 1665\n",
      "big 1659\n",
      "movie 1643\n",
      "born 1621\n",
      "series 1617\n",
      "love 1611\n",
      "down 1587\n",
      "family 1583\n",
      "game 1578\n",
      "around 1571\n",
      "between 1564\n",
      "will 1561\n",
      "white 1539\n",
      "line 1536\n",
      "set 1479\n",
      "during 1470\n",
      "place 1461\n",
      "know 1457\n",
      "long 1443\n",
      "sea 1432\n",
      "water 1432\n",
      "often 1422\n",
      "would 1420\n",
      "north 1415\n",
      "include 1409\n",
      "under 1408\n",
      "school 1403\n",
      "body 1386\n",
      "meaning 1378\n",
      "way 1366\n",
      "good 1361\n",
      "might 1358\n",
      "took 1342\n",
      "died 1340\n",
      "go 1316\n",
      "began 1315\n",
      "million 1310\n",
      "museum 1300\n",
      "musical 1298\n",
      "university 1291\n",
      "later 1289\n",
      "founded 1286\n",
      "small 1274\n",
      "best 1274\n",
      "use 1264\n",
      "god 1253\n",
      "gave 1247\n"
     ]
    }
   ],
   "source": [
    "most_freq_200 = fdist.most_common(200) # 200 most frequent words sorted by count\n",
    "for word, frequency in most_freq_200: # iterate and print\n",
    "    print word, frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the most frequent word is 'the' followed by 'of', then 'this' as the top 3. After a while the frequencies start to decrease but a slower rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph that shows the relative frequency of these 200 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3e49919b8068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relative Frequency of Words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Zipf Plot For 200 Most Common Words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    177\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                                 for label in axis.get_ticklabels()])\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mticksLight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# there are one or more tick labels, all with the same lightness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mget_ticklabels\u001b[0;34m(self, minor, which)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mget_majorticklabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0;34m'Return a list of Text instances for the major ticklabels'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m         \u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m         \u001b[0mlabels1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1On\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2On\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;34m'get the tick instances; grow as necessary'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumticks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0mnumticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/matplotlib/ticker.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;34m'Return the locations of the ticks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonboy1987/anaconda/lib/python2.7/site-packages/matplotlib/ticker.pyc\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m         \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2128\u001b[0;31m         \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "# compute the relative frequency and round it to 4 decimal places\n",
    "frequency = [x[1] for x in most_freq_200] # frequencies of words\n",
    "rel_frequency = [round(float(x)/n_words, 4) for x in frequency]\n",
    "plt.semilogx(frequency, rel_frequency) # log-scale\n",
    "plt.xlabel(\"log(Frequency) of Words in Jeopardy Questions\")\n",
    "plt.ylabel(\"Relative Frequency of Words\")\n",
    "plt.title(\"Zipf Plot For 200 Most Common Words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this plot shows as mentioned above that the lower-frequency words are mostly constant but slowly add up as the frequency changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the observed relative frequency of these words follow Zipfâ€™s law?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zipf's law: https://simple.wikipedia.org/wiki/Zipf%27s_law\n",
    "\n",
    "States that the frequency of a word is inversely porportional to it's rank in the frequency table.\n",
    "\n",
    "Even though the word 'the' doesn't appear twice as 'of' and not appear three times as 'this', there is a inversely porportional "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
